import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from app.state import AgentState
from app.services.rag_service import get_retriever

llm = ChatOpenAI(
    model="qwen-max", 
    temperature=0,
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_API_BASE")
)

def biz_node(state: AgentState):
    print("ðŸ“š [Biz Node] å¼€å§‹æŸ¥è¯¢ä¸šåŠ¡æ–‡æ¡£...")
    query = state['query']
    retriever = get_retriever()
    
    # æ£€ç´¢
    docs = retriever.invoke(query)
    context = "\n".join([d.page_content for d in docs]) or "æ— ç›¸å…³è®°å½•"
    
    # å›žç­”
    template = "åŸºäºŽä»¥ä¸‹æ–‡æ¡£å›žç­”é—®é¢˜ï¼š\n{context}\n\né—®é¢˜ï¼š{question}"
    chain = ChatPromptTemplate.from_template(template) | llm | StrOutputParser()
    res = chain.invoke({"context": context, "question": query})
    
    return {"final_answer": res}